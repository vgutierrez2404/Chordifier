{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np  \n",
    "import librosa \n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch  \n",
    "import torch.nn as nn   \n",
    "from typing import List\n",
    "import pytorch_lightning as pl  \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataframe = pd.read_csv('label_dataframe.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, feature = 'Chromagram',transform=None):\n",
    "        self.dataframe = dataframe['file_name']\n",
    "        self.root_dir = root_dir\n",
    "        self.feature = feature\n",
    "        self.transform = transform\n",
    "        self.label = dataframe['root_note']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "\n",
    "        if self.transform:\n",
    "            audio_data = self.transform(audio_data)\n",
    "        x, sr = librosa.load(audio_file, sr=None)\n",
    "        \n",
    "        return self.label[idx], self.get_features(x, sr, self.feature)\n",
    "    \n",
    "    def get_features(self, x, sr, feature='Chromagram'):\n",
    "        \n",
    "        rerturned_feature = np.empty((0, 0))     \n",
    "        hop_length = int(44.1e3*2)\n",
    "        if feature == 'Chromagram':\n",
    "            n_chroma = 12\n",
    "            n_octaves =7\n",
    "            rerturned_feature = librosa.feature.chroma_cqt(y=x, sr=sr, n_chroma=n_chroma, n_octaves=n_octaves, hop_length=hop_length)\n",
    "        \n",
    "        elif feature == 'Mel Spectrogram':\n",
    "            n_mels = 128    \n",
    "            n_fft = hop_length\n",
    "            rerturned_feature = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        else: pass # Implement other features\n",
    "\n",
    "        return rerturned_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['label', 'instrument', 'type_of_sound', 'chord_type']\n",
    "\n",
    "X = audio_dataframe.drop(columns=columns_to_drop, axis=1)\n",
    "y = audio_dataframe['root_note']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "train_dataloader = CustomDataset(dataframe=X_train, root_dir='IDMT-SMT-CHORDS/trimmed_audio', feature='Chromagram')\n",
    "test_dataloader = CustomDataset(dataframe=X_test, root_dir='IDMT-SMT-CHORDS/trimmed_audio', feature='Chromagram')\n",
    "val_dataloader = CustomDataset(dataframe=X_val, root_dir='IDMT-SMT-CHORDS/trimmed_audio', feature='Chromagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "\n",
    "    def forward(self, true_labels, estimated_labels):\n",
    "        # TODO: hay que cambiar la mse_loss por un cross entropy loss (categorical)\n",
    "        loss = F.mse_loss(true_labels, estimated_labels)\n",
    "        return {'MMSE loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chordifier_MLP(pl.LightningModule):\n",
    "\n",
    "    num_iter = 0  # Variable estática global para llevar la cuenta de las iteraciones\n",
    "\n",
    "    def __init__(self, in_channels: int = 16, out_channels: int = 1, hidden_dims: List = None, **kwargs):\n",
    "        super(Chordifier_MLP, self).__init__()\n",
    "        # Definición de variables internas\n",
    "        self.out_channels = out_channels\n",
    "        self.network = None\n",
    "        self.total_train_loss = 0\n",
    "        self.total_val_loss = 0\n",
    "        self.denom_train = 0\n",
    "        self.denom_val = 0\n",
    "\n",
    "        # Inicialización de dimensiones ocultas si no se proporcionan\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 16, 8, 4]\n",
    "        # Construye red MLP\n",
    "        self.build_network(in_channels, out_channels, hidden_dims)\n",
    "\n",
    "    def build_network(self, in_channels, out_channels, hidden_dims):\n",
    "        \"\"\"\n",
    "        Builds a neural network with the specified architecture.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            hidden_dims (list): List of integers representing the dimensions of the hidden layers.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Input and hidden layers\n",
    "        modules = []\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(nn.Sequential(\n",
    "                nn.Linear(in_features=in_channels, out_features=h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(num_features=h_dim)\n",
    "            ))\n",
    "            in_channels = h_dim\n",
    "        # Output layer\n",
    "        modules.append(nn.Sequential(\n",
    "            nn.Linear(in_features=in_channels, out_features=out_channels),\n",
    "            nn.ReLU() # Final ReLU activation: output is nonnegative (loss proxy)\n",
    "        ))\n",
    "\n",
    "        self.network = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input tensor to the model.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor from the model.\n",
    "        \"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "        input = input.to(torch.float32)\n",
    "\n",
    "        return self.network(input.to(device))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single training step.\n",
    "\n",
    "        Args:\n",
    "            batch: A tuple containing the true MSE and params_vector.\n",
    "            batch_idx: The index of the current batch.\n",
    "\n",
    "        Returns:\n",
    "            The MMSE loss for the current training step.\n",
    "        \"\"\"\n",
    "        label, feature_vector = batch\n",
    "        estimated_label = self.forward(feature_vector)\n",
    "        train_loss = CustomLoss()(label, torch.squeeze(estimated_label))\n",
    "        self.log_dict({key: val.item() for key, val in train_loss.items()}, sync_dist=True)\n",
    "        self.total_train_loss += train_loss['Train loss']\n",
    "        self.denom_train += 1\n",
    "\n",
    "        return train_loss['Train loss']\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a validation step on a batch of data.\n",
    "\n",
    "        Args:\n",
    "            batch: A tuple containing the true MSE and the parameters vector.\n",
    "            batch_idx: The index of the current batch.\n",
    "\n",
    "        Returns:\n",
    "            The MMSE loss for the validation step.\n",
    "        \"\"\"\n",
    "        label, feature_vector = batch\n",
    "        estimated_label = self.forward(feature_vector)\n",
    "        val_loss = CustomLoss()(label, torch.squeeze(estimated_label))\n",
    "        self.log_dict({f\"val_{key}\": val.item() for key, val in val_loss.items()}, sync_dist=True)\n",
    "        self.total_val_loss += val_loss['Validation loss']\n",
    "        self.denom_val += 1\n",
    "\n",
    "        return val_loss['Validation loss']\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of each validation epoch.\n",
    "\n",
    "        Prints the total losses for the current epoch.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if (self.denom_train == 0) or (self.denom_val == 0):\n",
    "            self.denom_train = 1\n",
    "            self.denom_val = 1\n",
    "        print(\n",
    "            f\"Epoch {self.current_epoch}: Train Loss = {self.total_train_loss / self.denom_train}, Validation Loss = {self.total_val_loss / self.denom_val}\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "            \"\"\"\n",
    "            Configures the optimizer for the model.\n",
    "\n",
    "            Returns:\n",
    "                optimizer (torch.optim.Optimizer): The configured optimizer.\n",
    "            \"\"\"\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "            return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
